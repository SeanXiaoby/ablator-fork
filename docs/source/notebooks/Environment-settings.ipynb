{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install Ablator via pip:\n",
    "```\n",
    "pip install ablator\n",
    "```\n",
    "For development version of Ablator:\n",
    "```\n",
    "pip install ablator[dev]\n",
    "```\n",
    "For  nightly release, install from `dev` branch of git repository:\n",
    "```\n",
    "pip install git+https://github.com/fostiropoulos/ablator.git@dev\n",
    "```\n",
    "\n",
    "Note: Python version is should be 3.10 or newer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up ray cluster\n",
    "This section provides steps to set up a ray cluster manually for a set of machines that share the same network. However, there are several other ways to set up a ray cluster (AWS, GCP, or Kubernetes). Refer to [ray clusters docs](https://docs.ray.io/en/latest/cluster/getting-started.html#cluster-index) for other methods.\n",
    "\n",
    "We assume that `ablator` (which includes `ray`) is already installed on each machine.\n",
    "\n",
    "##### Start the Head node\n",
    "Choose any node to be the head node and run the following. Note that Ray will choose port 6379 by default:\n",
    "```\n",
    "ray start --head\n",
    "```\n",
    "The command will print out the Ray cluster address, which can be passed to ray start on other machines to start the worker nodes (see below). If you receive a ConnectionError, check your firewall settings and network configuration.\n",
    "\n",
    "##### Start Worker nodes\n",
    "On each of the other nodes, run the following command to connect to the head node you just created:\n",
    "```\n",
    "ray start --address=<head-node-address:port>\n",
    "```\n",
    "`head-node-address:port` should be the value printed by the command on the head node (it should look something like `123.45.67.89:6379`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "This tutorial for setting up ray cluster is adapted from [this ray doc](https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/on-premises.html). Here you can find instructions to alternatively launch the ray cluster using `cluster-launcher`, which sets up all nodes at once instead of manually going over each of the node.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU-Accelerated Computing (Optional)\n",
    "If you have GPUs available, you can run your experiments wth GPU acceleration, which can significantly speed up the training process. To run CUDA Python, youâ€™ll need the [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) installed on your system with CUDA-capable GPUs.\n",
    "\n",
    "After setting up CUDA, you can install the cuda-enabled torch package. Refer to [this tutorial](https://pytorch.org/get-started/locally/) for instructions on how to install cuda enabled package. A sample command to install torch cuda package can be found below:\n",
    "```\n",
    "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu117 --force-reinstall\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
